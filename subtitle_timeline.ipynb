{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "subtitle_timeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNrkcZW7WPhv+DEqVrsWn/O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2199465703b4458e9e7e745faa1a2cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_623cb42ca92d4278a8ab67ba6450c127",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03f5fc73c656485c80f08f09672ff8b2",
              "IPY_MODEL_0966feb374a74eec90092cdedb87828e"
            ]
          }
        },
        "623cb42ca92d4278a8ab67ba6450c127": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "03f5fc73c656485c80f08f09672ff8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5faffa4c819c4ad5858b1461d1d8ed42",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 117375227,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 117375227,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_68b76c32d0854b86950feee84ad77b72"
          }
        },
        "0966feb374a74eec90092cdedb87828e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d80ab4c28124fadbdea933a817ff5a0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112M/112M [03:42&lt;00:00, 527kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_844371aaa62846f382bcb0b1d031198a"
          }
        },
        "5faffa4c819c4ad5858b1461d1d8ed42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "68b76c32d0854b86950feee84ad77b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d80ab4c28124fadbdea933a817ff5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "844371aaa62846f382bcb0b1d031198a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/profteachkids/subtitle_generator/blob/main/subtitle_timeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "aqdi3Ry9vUZW",
        "outputId": "a5c97b92-3adc-4c2e-d1bd-352905d05445"
      },
      "source": [
        "!pip install biopython\n",
        "!pip install bidict\n",
        "!pip install omegaconf\n",
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting biopython\n",
            "  Downloading biopython-1.79-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython) (1.19.5)\n",
            "Installing collected packages: biopython\n",
            "Successfully installed biopython-1.79\n",
            "Collecting bidict\n",
            "  Downloading bidict-0.21.2-py2.py3-none-any.whl (37 kB)\n",
            "Installing collected packages: bidict\n",
            "Successfully installed bidict-0.21.2\n",
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 386 kB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 10.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=61ad9dc2e95f665460310c4aca52798fc5ddfa5af328af0993cfde51a5efd11e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, omegaconf\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 omegaconf-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "  Downloading torchaudio-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchaudio) (3.7.4.3)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AyMWoVjJvCHP"
      },
      "source": [
        "import numpy as np\n",
        "from lxml import etree\n",
        "import subprocess as sp\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from Bio import pairwise2\n",
        "from Bio.pairwise2 import format_alignment\n",
        "from bidict import bidict\n",
        "import string\n",
        "from glob import glob\n",
        "import re\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klBr8oQUvKwk"
      },
      "source": [
        "text = \"\"\"after the questionable\n",
        "events of the last part\n",
        "where Spadeless lost\n",
        "his pets\"\"\"\n",
        "\n",
        "text = re.sub(r\"[,.!?-] \", \" \", text, 0, re.MULTILINE)\n",
        "text = text.lower()\n",
        "text = text.split()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdMYHhrEvhwQ"
      },
      "source": [
        "DEVNULL = open(os.devnull, \"w\")\n",
        "\n",
        "def ffmpeg_load_audio(\n",
        "    filename,\n",
        "    sr=44100,\n",
        "    mono=False,\n",
        "    normalize=True,\n",
        "    in_type=np.int16,\n",
        "    out_type=np.float32,\n",
        "):\n",
        "    channels = 1 if mono else 2\n",
        "    format_strings = {\n",
        "        np.float64: \"f64le\",\n",
        "        np.float32: \"f32le\",\n",
        "        np.int16: \"s16le\",\n",
        "        np.int32: \"s32le\",\n",
        "        np.uint32: \"u32le\",\n",
        "    }\n",
        "    format_string = format_strings[in_type]\n",
        "    command = [\n",
        "        \"ffmpeg\",\n",
        "        \"-i\",\n",
        "        filename,\n",
        "        \"-f\",\n",
        "        format_string,\n",
        "        \"-acodec\",\n",
        "        \"pcm_\" + format_string,\n",
        "        \"-ar\",\n",
        "        str(sr),\n",
        "        \"-ac\",\n",
        "        str(channels),\n",
        "        \"-\",\n",
        "    ]\n",
        "    p = sp.Popen(command, stdout=sp.PIPE, stderr=DEVNULL, bufsize=4096)\n",
        "    bytes_per_sample = np.dtype(in_type).itemsize\n",
        "    frame_size = bytes_per_sample * channels\n",
        "    chunk_size = frame_size * sr  # read in 1-second chunks\n",
        "    raw = b\"\"\n",
        "    with p.stdout as stdout:\n",
        "        while True:\n",
        "            data = stdout.read(chunk_size)\n",
        "            if data:\n",
        "                raw += data\n",
        "            else:\n",
        "                break\n",
        "    audio = np.fromstring(raw, dtype=in_type).astype(out_type)\n",
        "    if channels > 1:\n",
        "        audio = audio.reshape((-1, channels)).transpose()\n",
        "    if audio.size == 0:\n",
        "        return audio, sr\n",
        "    if issubclass(out_type, np.floating):\n",
        "        if normalize:\n",
        "            peak = np.abs(audio).max()\n",
        "            if peak > 0:\n",
        "                audio /= peak\n",
        "        elif issubclass(in_type, np.integer):\n",
        "            audio /= np.iinfo(in_type).max\n",
        "    return audio, sr\n",
        "\n",
        "def to_text(f):\n",
        "    print(f)\n",
        "    audio, sr = ffmpeg_load_audio(\n",
        "        f, sr=16000, in_type=np.float32, out_type=np.float32\n",
        "    )\n",
        "    audio = np.expand_dims(audio.astype(np.float32)[0], 0)\n",
        "\n",
        "\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('loading')\n",
        "    model, decoder, utils = torch.hub.load(\n",
        "        repo_or_dir=\"snakers4/silero-models\",\n",
        "        model=\"silero_stt\",\n",
        "        language=\"en\",  # also available 'de', 'es'\n",
        "        device=device,\n",
        "    )\n",
        "    print('finished loading')\n",
        "\n",
        "    res = []\n",
        "    batch_size =  3*sr\n",
        "    N = audio.size // batch_size\n",
        "\n",
        "    sections = np.array_split(audio, N, 1)\n",
        "    section_start=0\n",
        "    for i, section in enumerate(sections):\n",
        "        input=torch.from_numpy(section)\n",
        "        output = model(input)[0]\n",
        "        decoded=decoder(output.cpu(), section.size, word_align=True)\n",
        "        if len(decoded)==2:\n",
        "            s,dlist = decoded\n",
        "            for d in dlist:\n",
        "                d[\"start_ts\"] = (d[\"start_ts\"] + section_start)/sr\n",
        "                d[\"end_ts\"] = (d[\"end_ts\"] +  section_start)/sr\n",
        "                print(d[\"word\"], d[\"start_ts\"], d[\"end_ts\"])\n",
        "                res.append(d)\n",
        "            section_start+=section.size\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(res)\n",
        "    df.to_csv(\"voice_times.csv\")\n",
        "\n",
        "    voice_words = df[\"word\"].values\n",
        "    print(\" \".join(voice_words))\n",
        "\n",
        "def align():\n",
        "    df = pd.read_csv(\"voice_times.csv\")\n",
        "    voice_words = df[\"word\"].values\n",
        "    start_times = df[\"start_ts\"].values\n",
        "    end_times = df[\"end_ts\"].values\n",
        "\n",
        "    all_words = set(text).union(set(voice_words))\n",
        "\n",
        "    word_dict = bidict(zip(all_words, range(len(all_words))))\n",
        "    word_dict[\"-\"] = \"-\"\n",
        "    voice = [word_dict[word] for word in voice_words]\n",
        "    script = [word_dict[word] for word in text]\n",
        "    align = pairwise2.align.globalxx(voice, script, gap_char =['-'], one_alignment_only=True)[0]\n",
        "    matches=[]\n",
        "    mismatches=[]\n",
        "    mismatch_voice=word_dict.inverse[align.seqA[0]]   \n",
        "    mismatch_text=word_dict.inverse[align.seqB[0]]\n",
        "    v_end_pos=0\n",
        "    v_start_pos=0\n",
        "    t_end_pos=0\n",
        "    t_start_pos=0\n",
        "    for i,(v, t) in enumerate(zip(align.seqA[1:], align.seqB[1:])):\n",
        "        print(word_dict.inverse[v], word_dict.inverse[t])\n",
        "        if v==t:\n",
        "            mismatches.append([t_start_pos, t_end_pos, start_times[v_start_pos], end_times[v_end_pos], mismatch_voice, mismatch_text])\n",
        "            v_end_pos+=1\n",
        "            v_start_pos=v_end_pos\n",
        "            t_end_pos+=1\n",
        "            t_start_pos=t_end_pos\n",
        "            mismatch_voice=word_dict.inverse[v]\n",
        "            mismatch_text=word_dict.inverse[t]\n",
        "        else:\n",
        "            if word_dict.inverse[v] != '-' :\n",
        "                v_end_pos+=1\n",
        "            if word_dict.inverse[t] != '-' :\n",
        "                t_end_pos+=1\n",
        "            mismatch_voice+=' ' + word_dict.inverse[v]\n",
        "            mismatch_text+=' ' + word_dict.inverse[t]\n",
        "\n",
        "\n",
        "    mismatches.append([t_start_pos, t_end_pos, start_times[v_start_pos], end_times[v_end_pos], mismatch_voice, mismatch_text])\n",
        "\n",
        "    idx=[]\n",
        "    times=[]\n",
        "    for t_start_pos, t_end_pos, start_time, end_time, v, t in mismatches:\n",
        "        print('-'*30)\n",
        "        print(v)\n",
        "        print(t)\n",
        "        print(t_start_pos,t_end_pos, start_time, end_time)\n",
        "        d={}\n",
        "\n",
        "        t2 = t.translate(t.maketrans(string.punctuation, \" \" * len(string.punctuation)))\n",
        "        t2 = \" \".join(t2.split())\n",
        "\n",
        "        idx.append(t_start_pos)\n",
        "        times.append(start_time)\n",
        "\n",
        "    idx.append(t_end_pos+1)\n",
        "    times.append(end_time)\n",
        "\n",
        "    np.savez('it',idx=np.array(idx),time=np.array(times))\n",
        "    it = np.load('it.npz')\n",
        "    print(it['idx'], len(it['idx']))\n",
        "    print(it['time'], len(it['time']))\n",
        "\n",
        "def make_copies():\n",
        "    it = np.load('it.npz')\n",
        "    idx=it['idx']\n",
        "    times=it['time']\n",
        "    print(times, len(times))\n",
        "    path_out='E:\\\\Blender\\\\BlenderVideo\\\\'\n",
        "    path_in='E:\\\\Blender\\\\BlenderOut\\\\'\n",
        "\n",
        "    i=0\n",
        "    subtitle_images = glob(path_in+'*.png')\n",
        "    print(subtitle_images)\n",
        "    for subtitle_image in subtitle_images:\n",
        "        name, subtitle_n, w_start, w_end = subtitle_image.split('_')\n",
        "        *_, name = name.split('\\\\')\n",
        "        w_end,_ = w_end.split('.')\n",
        "        w_start, w_end, subtitle_n =int(w_start), int(w_end), int(subtitle_n)\n",
        "        t_start, t_end = np.interp([w_start, w_end], idx, times)\n",
        "        f_start, f_end = int(t_start*10), int(t_end*10)\n",
        "        print(name, w_start, w_end, t_start, t_end, f_start, f_end)\n",
        "        for copy_n in range(f_end-f_start+1):\n",
        "            \n",
        "            name=f'{i:04d}'.translate(str.maketrans('0123456789','abcdefghij'))\n",
        "            shutil.copyfile(subtitle_image, path_out+name+'.png')\n",
        "            i+=1\n",
        "\n",
        "def set_timeline():\n",
        "    it = np.load('it.npz')\n",
        "    idx=it['idx']\n",
        "    times=it['time']\n",
        "\n",
        "\n",
        "    tree = etree.parse('Timeline 1.xml')\n",
        "    clips=tree.xpath('//video//clipitem')\n",
        "    for clip in clips:\n",
        "        name=clip.xpath('name/text()')[0]\n",
        "        start=clip.xpath('start')[0]\n",
        "        end=clip.xpath('end')[0]\n",
        "        name, subtitle_n, w_start, w_end = name.split('_')\n",
        "        *_, name = name.split('\\\\')\n",
        "        w_end,_ = w_end.split('.')\n",
        "        w_start, w_end, subtitle_n =int(w_start), int(w_end), int(subtitle_n)\n",
        "        t_start, t_end = np.interp([w_start, w_end], idx, times)\n",
        "        start.text=str(int(t_start*60))\n",
        "        end.text=str(int(t_end*60))\n",
        "\n",
        "    f = open('subtitle_timeline.xml', 'wb')\n",
        "    f.write(etree.tostring(tree, pretty_print=True))\n",
        "    f.close()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2199465703b4458e9e7e745faa1a2cd5",
            "623cb42ca92d4278a8ab67ba6450c127",
            "03f5fc73c656485c80f08f09672ff8b2",
            "0966feb374a74eec90092cdedb87828e",
            "5faffa4c819c4ad5858b1461d1d8ed42",
            "68b76c32d0854b86950feee84ad77b72",
            "6d80ab4c28124fadbdea933a817ff5a0",
            "844371aaa62846f382bcb0b1d031198a"
          ]
        },
        "id": "Wrcr7GBpv8dz",
        "outputId": "5c27f6ae-a6fc-426a-db16-9e9ff512ade2"
      },
      "source": [
        "to_text(\"audio.mov\")\n",
        "align()    \n",
        "set_timeline()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "audio.mov\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
            "Downloading: \"https://github.com/snakers4/silero-models/archive/master.zip\" to /root/.cache/torch/hub/master.zip\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loading\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2199465703b4458e9e7e745faa1a2cd5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=117375227.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "finished loading\n",
            "after 0.118656875 0.43507437499999996\n",
            "the 0.5932837500000001 0.8305968749999999\n",
            "questionable 0.8305968749999999 1.423880625\n",
            "events 1.423880625 1.7798506250000001\n",
            "of 1.858955 2.05671625\n",
            "the 2.05671625 2.2544775\n",
            "last 2.2544775 2.4917912500000003\n",
            "part 2.4917912500000003 2.729104375\n",
            "were 2.887313125 3.124626875\n",
            "spedless 3.124626875 3.6783581250000004\n",
            "moss 3.7574625 4.152984999999999\n",
            "his 4.152984999999999 4.39029875\n",
            "pets 4.4694031249999995 4.864925625\n",
            "after the questionable events of the last part were spedless moss his pets\n",
            "the the\n",
            "questionable questionable\n",
            "events events\n",
            "of of\n",
            "the the\n",
            "last last\n",
            "part part\n",
            "were -\n",
            "spedless -\n",
            "moss -\n",
            "- where\n",
            "- spadeless\n",
            "- lost\n",
            "his his\n",
            "pets pets\n",
            "------------------------------\n",
            "after\n",
            "after\n",
            "0 0 0.118656875 0.435074375\n",
            "------------------------------\n",
            "the\n",
            "the\n",
            "1 1 0.5932837500000001 0.8305968749999999\n",
            "------------------------------\n",
            "questionable\n",
            "questionable\n",
            "2 2 0.8305968749999999 1.423880625\n",
            "------------------------------\n",
            "events\n",
            "events\n",
            "3 3 1.423880625 1.779850625\n",
            "------------------------------\n",
            "of\n",
            "of\n",
            "4 4 1.858955 2.05671625\n",
            "------------------------------\n",
            "the\n",
            "the\n",
            "5 5 2.05671625 2.2544775\n",
            "------------------------------\n",
            "last\n",
            "last\n",
            "6 6 2.2544775 2.4917912500000003\n",
            "------------------------------\n",
            "part were spedless moss - - -\n",
            "part - - - where spadeless lost\n",
            "7 10 2.4917912500000003 4.152984999999998\n",
            "------------------------------\n",
            "his\n",
            "his\n",
            "11 11 4.152984999999998 4.39029875\n",
            "------------------------------\n",
            "pets\n",
            "pets\n",
            "12 12 4.469403125 4.864925625\n",
            "[ 0  1  2  3  4  5  6  7 11 12 13] 11\n",
            "[0.11865687 0.59328375 0.83059687 1.42388063 1.858955   2.05671625\n",
            " 2.2544775  2.49179125 4.152985   4.46940313 4.86492562] 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1051: UserWarning: stft will soon require the return_complex parameter be given for real inputs, and will further require that return_complex=True in a future PyTorch release. (Triggered internally at  /pytorch/aten/src/ATen/native/SpectralOps.cpp:664.)\n",
            "  return forward_call(*input, **kwargs)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSoGeI0jwZCq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}